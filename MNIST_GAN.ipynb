{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZP2zEK7YUL6",
        "colab_type": "text"
      },
      "source": [
        "Vamos a usar este notebook como ejemplo de redes GAN. Estas se componen de dos redes: una generadora y otra discriminadora. La generadora tratará de crear instancias de datos falsos que tratará de \"colar\" entre los datos reales provenientes del dataset que se le pasarán a la discriminadora. Usaremos el datast de MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-LdMWHyTzu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "%tensorflow_version 1.x\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.models import Model,Sequential\n",
        "from keras.datasets import mnist\n",
        "from tqdm import tqdm\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8r8PKQWUNFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
        "  \n",
        "  # convert shape of x_train from (60000, 28, 28) to (60000, 784) \n",
        "  # 784 columns per row\n",
        "  x_train = x_train.reshape(60000, 784)\n",
        "  return (x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pnXFsfbW12R",
        "colab_type": "code",
        "outputId": "ef4ebbba-25f4-4a7e-d400-87734252083d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "(X_train, y_train,X_test, y_test)=load_data()\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4zhNFxEUZdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_generator():\n",
        "  generator=Sequential()\n",
        "  generator.add(Dense(units=256,input_dim=100))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  \n",
        "  generator.add(Dense(units=512))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  \n",
        "  generator.add(Dense(units=1024))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  \n",
        "  generator.add(Dense(units=784, activation='tanh'))\n",
        "  \n",
        "  generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMFCnrUgW90J",
        "colab_type": "code",
        "outputId": "3ec709c5-b203-4fe9-bd83-76e80f7b5dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "g = create_generator()\n",
        "g.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 784)               803600    \n",
            "=================================================================\n",
            "Total params: 1,486,352\n",
            "Trainable params: 1,486,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3HRJZqsVJEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_discriminator():\n",
        "  discriminator=Sequential()\n",
        "  discriminator.add(Dense(units=1024,input_dim=784))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "      \n",
        "  \n",
        "  discriminator.add(Dense(units=512))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "      \n",
        "  discriminator.add(Dense(units=256))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  \n",
        "  discriminator.add(Dense(units=1, activation='sigmoid'))\n",
        "  \n",
        "  discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XegTTvzcXBYE",
        "colab_type": "code",
        "outputId": "9a271d76-155c-47c1-f623-9fe1cda21a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "d = create_discriminator()\n",
        "d.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 1024)              803840    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 1,460,225\n",
            "Trainable params: 1,460,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oP3ugxWV220",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_gan(discriminator, generator):\n",
        "  discriminator.trainable=False\n",
        "  gan_input = Input(shape=(100,))\n",
        "  x = generator(gan_input)\n",
        "  gan_output= discriminator(x)\n",
        "  gan= Model(inputs=gan_input, outputs=gan_output)\n",
        "  gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  return gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6S5Yo9wWXmF",
        "colab_type": "code",
        "outputId": "d77d1998-4afd-448a-db93-f85b2ef3b8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "gan = create_gan(d, g)\n",
        "gan.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 784)               1486352   \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 1)                 1460225   \n",
            "=================================================================\n",
            "Total params: 2,946,577\n",
            "Trainable params: 1,486,352\n",
            "Non-trainable params: 1,460,225\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TfG7sdPaVFw",
        "colab_type": "text"
      },
      "source": [
        "# plot_generated_images\n",
        "Imprimimos las imágenes generadas para ver cómo va evolucionando la generación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgX-SNuHWodP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_generated_images(epoch, generator, examples=100, dim=(10,10), figsize=(10,10)):\n",
        "  noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
        "  generated_images = generator.predict(noise)\n",
        "  generated_images = generated_images.reshape(100,28,28)\n",
        "  plt.figure(figsize=figsize)\n",
        "  for i in range(generated_images.shape[0]):\n",
        "    plt.subplot(dim[0], dim[1], i+1)\n",
        "    plt.imshow(generated_images[i], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.savefig('gan_generated_image %d.png' %epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9qObGebbPiN",
        "colab_type": "text"
      },
      "source": [
        "# train_gan\n",
        "Entrenamos la GAN. Para ello primero cargamos los datos de entrenamiento y test del dataset. A continuación creamos un generador, un discriminador y, con ellos, la GAN.\n",
        "\n",
        "## En cada instante \n",
        "Generamos ruido aleatorio para inicializar el generador. Este crea dígitos falsos de MNIST. Con estos dígitos falsos y otros verdaderos tomados aleatoriamente del dataset, creamos un \"batch\" o conjunto de imágenes. Pasaremos estos batches al discriminador. También crearemos etiquetas para los datos reales y generados.\n",
        "Luego pre-entrenaremos al discriminador con datos tanto falsos como reales antes de iniciar la GAN. Así nos aseguramos de que el modelo funcione correctamente con ambos tipos de datos.\n",
        "A continuación tomamos las imágenes generadas y las hacemos pasar por datos auténticos.\n",
        "Para entrenar la GAN debemos entrenar al discriminador, y luego congelar sus pesos y entrenar el resto del modelo.\n",
        "\n",
        "Finalmente, cada 20 instantes mostramos las imágenes generadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7oGg2kjXZDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gan(epochs=1, batch_size=128):\n",
        "    \n",
        "  # Loading data\n",
        "  (X_train, y_train, X_test, y_test) = load_data()\n",
        "  batch_count = X_train.shape[0] / batch_size\n",
        "  \n",
        "  # Create GAN\n",
        "  generator = create_generator()\n",
        "  discriminator = create_discriminator()\n",
        "  gan = create_gan(discriminator, generator)\n",
        "  \n",
        "  for e in range(1,epochs+1 ):\n",
        "    print(\"Epoch %d\" %e)\n",
        "    for _ in tqdm(range(batch_size)): # We use tqdm to show a progress bar of the for loop\n",
        "      # Generate random noise as an input to initialize the generator\n",
        "      noise = np.random.normal(0,1, [batch_size, 100])\n",
        "      \n",
        "      # Generate fake MNIST images from noised input\n",
        "      generated_images = generator.predict(noise)\n",
        "      \n",
        "      # Get a random set of real images\n",
        "      image_batch = X_train[np.random.randint(low=0, high=X_train.shape[0], size=batch_size)]\n",
        "      \n",
        "      # Construct different batches of real and fake data \n",
        "      X = np.concatenate([image_batch, generated_images])\n",
        "      \n",
        "      # Labels for generated and real data\n",
        "      y_dis = np.zeros(2 * batch_size)\n",
        "      y_dis[:batch_size] = 0.9\n",
        "      \n",
        "      # Pre train discriminator on  fake and real data  before starting the gan. \n",
        "      discriminator.trainable = True\n",
        "      discriminator.train_on_batch(X, y_dis)\n",
        "      \n",
        "      # Tricking the noised input of the Generator as real data\n",
        "      noise = np.random.normal(0,1, [batch_size, 100])\n",
        "      y_gen = np.ones(batch_size)\n",
        "      \n",
        "      # During the training of gan, \n",
        "      # the weights of discriminator should be fixed. \n",
        "      # We can enforce that by setting the trainable flag\n",
        "      discriminator.trainable = False\n",
        "      \n",
        "      # training the GAN by alternating the training of the Discriminator \n",
        "      # and training the chained GAN model with Discriminator’s weights freezed.\n",
        "      gan.train_on_batch(noise, y_gen)\n",
        "          \n",
        "      if e == 1 or e % 20 == 0:\n",
        "        plot_generated_images(e, generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdKadAYJXhTk",
        "colab_type": "code",
        "outputId": "01929828-6b1c-403f-ab5f-66261856cbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_gan(400,128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/128 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 20/128 [01:06<05:37,  3.12s/it]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  \"\"\"\n",
            "100%|██████████| 128/128 [06:56<00:00,  2.66s/it]\n",
            "  1%|          | 1/128 [00:00<00:21,  6.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:23<00:00,  5.60it/s]\n",
            "  1%|          | 1/128 [00:00<00:22,  5.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:21<00:00,  6.08it/s]\n",
            "  1%|          | 1/128 [00:00<00:22,  5.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.16it/s]\n",
            "  1%|          | 1/128 [00:00<00:19,  6.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.04it/s]\n",
            "  1%|          | 1/128 [00:00<00:21,  5.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:21<00:00,  5.82it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:21<00:00,  6.01it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  5.88it/s]\n",
            "  1%|          | 1/128 [00:00<00:22,  5.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.10it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.17it/s]\n",
            "  1%|          | 1/128 [00:00<00:19,  6.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.02it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:21<00:00,  5.99it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:21<00:00,  6.07it/s]\n",
            "  1%|          | 1/128 [00:00<00:21,  5.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.19it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:21<00:00,  6.08it/s]\n",
            "  1%|          | 1/128 [00:00<00:21,  6.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:21<00:00,  6.16it/s]\n",
            "  1%|          | 1/128 [00:00<00:21,  5.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:21<00:00,  6.24it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.03it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.18it/s]\n",
            "  0%|          | 0/128 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [06:45<00:00,  2.56s/it]\n",
            "  1%|          | 1/128 [00:00<00:22,  5.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:24<00:00,  6.00it/s]\n",
            "  1%|          | 1/128 [00:00<00:21,  5.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.16it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  5.92it/s]\n",
            "  1%|          | 1/128 [00:00<00:21,  5.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.43it/s]\n",
            "  1%|          | 1/128 [00:00<00:21,  6.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.53it/s]\n",
            "  1%|          | 1/128 [00:00<00:19,  6.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.68it/s]\n",
            "  1%|          | 1/128 [00:00<00:19,  6.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.34it/s]\n",
            "  1%|          | 1/128 [00:00<00:19,  6.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:20<00:00,  6.49it/s]\n",
            "  1%|          | 1/128 [00:00<00:19,  6.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.48it/s]\n",
            "  1%|          | 1/128 [00:00<00:19,  6.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.61it/s]\n",
            "  1%|          | 1/128 [00:00<00:18,  6.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.69it/s]\n",
            "  1%|          | 1/128 [00:00<00:18,  7.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.68it/s]\n",
            "  1%|          | 1/128 [00:00<00:19,  6.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.38it/s]\n",
            "  1%|          | 1/128 [00:00<00:18,  6.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.77it/s]\n",
            "  1%|          | 1/128 [00:00<00:18,  6.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.26it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.62it/s]\n",
            "  1%|          | 1/128 [00:00<00:20,  6.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.66it/s]\n",
            "  1%|          | 1/128 [00:00<00:18,  6.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.36it/s]\n",
            "  1%|          | 1/128 [00:00<00:19,  6.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:19<00:00,  6.51it/s]\n",
            "  0%|          | 0/128 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 93/128 [04:37<01:31,  2.62s/it]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}